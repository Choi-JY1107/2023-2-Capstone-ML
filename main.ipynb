{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPCWr+n5bvDrayx+0d3DqAY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 구글 드라이브 연결"],"metadata":{"id":"kYPEoYKKTvZC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ApcUPMc-Zdsu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [Step 0] 초기 설정"],"metadata":{"id":"wzUycd6iTyXk"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import shutil\n","from PIL import Image\n","from numpy import expand_dims\n","from keras.api._v2.keras import activations\n","from tensorflow import keras\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from tensorflow.python.client import device_lib\n","from datetime import datetime\n","import json\n","\n","data_path = os.getcwd() + '/drive/MyDrive/2023-2-Capstone-ML/dataset/'\n","model_path = os.getcwd() + '/drive/MyDrive/2023-2-Capstone-ML/model/'\n","ori_path = data_path + 'pet_img/'\n","\n","\n","data_dir = data_path + 'gen_img/'\n","train_dir = data_path + 'train_ds'\n","validation_dir = data_path + 'val_ds'\n","test_ratio = 0.2"],"metadata":{"id":"H9IqRwGRc6uS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [Step 1] 이미지 증식 함수"],"metadata":{"id":"QTHUcB75b7UX"}},{"cell_type":"markdown","source":["## 이미지 증식 클래스"],"metadata":{"id":"hwiFvFl2xuWo"}},{"cell_type":"code","source":["class ImageProcess:\n","    def __init__(self, path=None, name=None, num=None, dir_path=None):\n","        self.image = Image.open(path)\n","        self.size = (224, 224)\n","        self.path = path\n","        self.name = name\n","        self.num = num\n","        self.dir_path = dir_path\n","\n","    def image_processing(self):\n","        self.image = self.image.resize(self.size)\n","        image_array = np.asarray(self.image)\n","        image_array = image_array / 255.0\n","        return image_array\n","\n","    def image_generator(self):\n","        img = Image.open(self.path)\n","        img = img.resize(self.size)\n","        img_array = img_to_array(img)\n","        img_array = img_array.reshape((1,) + img_array.shape)\n","        datagen = ImageDataGenerator(\n","            rotation_range=20,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            shear_range=0.2,\n","            zoom_range=0.2,\n","            horizontal_flip=True,\n","            brightness_range=[0.7, 1.3],\n","            fill_mode='nearest')\n","\n","        num_augmented_images = 30\n","        i = 0\n","\n","        for batch in datagen.flow(img_array, batch_size=1):\n","          augmented_image = array_to_img(batch[0])\n","          augmented_image.save(self.dir_path + self.name + '_' + str(self.num) + '.jpg')\n","          i += 1\n","          self.num += 1\n","          if i >= num_augmented_images:\n","            break\n","        return self.num\n"],"metadata":{"id":"0cS0_Y_pQ4TH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def path_setting(img_name):\n","  gen_path = data_path + 'gen_img/' + img_name + '/'\n","  train_path = data_path + 'train_img/' + img_name + '/'\n","  test_path = data_path + 'test_img/' + img_name + '/'\n","  pet_path = ori_path + img_name\n","  return gen_path, train_path, test_path, pet_path\n","\n","def generator_img(img_name):\n","  gen_path, train_path, test_path, pet_path = path_setting(img_name)\n","\n","  # 디렉토리 생성\n","  os.makedirs(gen_path, exist_ok=True)\n","  os.makedirs(train_path, exist_ok=True)\n","  os.makedirs(test_path, exist_ok=True)\n","\n","  # 증식 실시할 데이터 지정\n","  pet_img_list = []\n","  for img in os.listdir(pet_path):\n","    pet_img_list.append(img)\n","\n","  # 학습용, 테스트용 데이터 분리\n","  img_count = len(pet_img_list)\n","  test_count = int(img_count * test_ratio)\n","  test_img_list = np.random.choice(pet_img_list, test_count, False)\n","  train_idx = np.where(np.isin(pet_img_list, test_img_list) == False)[0]\n","  train_img_list = np.array(pet_img_list)[train_idx]\n","\n","  # 테스트용 데이터 저장\n","  test_idx = 0\n","  for img in test_img_list :\n","    pet_img_path = pet_path + '/' + str(img)\n","    test_img_path = test_path + str(img)[:-4] + '_' + str(test_idx) + '.jpg'\n","    test_idx += 1\n","    shutil.copyfile(pet_img_path, test_img_path)\n","    print(pet_img_path + \"에 있는 이미지를 \" + test_img_path + \"에 복사\")\n","  print(str(img_name) + \"번 동물 테스트 사진 \" + str(test_idx) + \"개 생성\")\n","\n","  # 학습용 데이터 저장 및 증식\n","  train_idx = 0\n","  for img in train_img_list :\n","    pet_img_path = pet_path + '/' + str(img)\n","    train_img_path = train_path + str(img)[:-4] + '_' + str(train_idx) + '.jpg'\n","    train_idx += 1\n","    shutil.copyfile(pet_img_path, train_img_path)\n","    print(pet_img_path + \"에 있는 이미지를 \" + train_img_path + \"에 복사\")\n","\n","    # 데이터 증식\n","    obj = ImageProcess(train_img_path, str(img)[:-4], train_idx, gen_path)\n","    train_idx = obj.image_generator()\n","  print(str(img_name) + \"번 동물 학습 사진 \" + str(train_idx) + \"개 증식\")\n"],"metadata":{"id":"36ex1Zxob9JC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for pet in os.listdir(ori_path):\n","  generator_img(pet)"],"metadata":{"id":"Idesh3B8T75w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [Step 2] train, valid 데이터 분리"],"metadata":{"id":"jDrwDMI6OrKV"}},{"cell_type":"code","source":["def split_train_valid() :\n","  # 경로 생성\n","  os.makedirs(train_dir, exist_ok=True)\n","  os.makedirs(validation_dir, exist_ok=True)\n","\n","  subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n","\n","  # train, validation 분리\n","  for subdir in subdirs:\n","    subdir_path = os.path.join(data_dir, subdir)\n","    images = [f for f in os.listdir(subdir_path) if f.endswith('.jpg')]\n","    train_images, validation_images = train_test_split(images, test_size=0.2, random_state=42)\n","\n","    # Move images to training directory\n","    for image in train_images:\n","        source = os.path.join(subdir_path, image)\n","        destination = os.path.join(train_dir, subdir, image)\n","        os.makedirs(os.path.dirname(destination), exist_ok=True)\n","        shutil.copy(source, destination)\n","\n","    # Move images to validation directory\n","    for image in validation_images:\n","        source = os.path.join(subdir_path, image)\n","        destination = os.path.join(validation_dir, subdir, image)\n","        os.makedirs(os.path.dirname(destination), exist_ok=True)\n","        shutil.copy(source, destination)\n","    print(str(subdir) + \"번 사진 \" + str(len(train_images) + len(validation_images)) + \"개를 추가하였습니다.\")\n","split_train_valid()"],"metadata":{"id":"SH61oaAK6SEr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [Step 3] 학습"],"metadata":{"id":"sHqWS2Z36G9M"}},{"cell_type":"markdown","source":["## 이미지 학습 클래스"],"metadata":{"id":"Rflk2ENXPHA5"}},{"cell_type":"code","source":["class EfficientNet:\n","    def training_model(self):\n","      train_datagen = ImageDataGenerator(\n","            rescale=1./255,\n","            rotation_range=20,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            shear_range=0.2,\n","            zoom_range=0.2,\n","            horizontal_flip=True,\n","            brightness_range=[0.7, 1.3],\n","            fill_mode='nearest'\n","      )\n","\n","      # Define data augmentation for validation images\n","      validation_datagen = ImageDataGenerator(\n","          rescale=1./255\n","      )\n","\n","      # Create data generators\n","      batch_size = 16\n","      train_generator = train_datagen.flow_from_directory(\n","          train_dir,\n","          target_size=(224, 224),\n","          batch_size=batch_size,\n","          class_mode='categorical')\n","\n","      validation_generator = validation_datagen.flow_from_directory(\n","          validation_dir,\n","          target_size=(224, 224),\n","          batch_size=batch_size,\n","          class_mode='categorical')\n","\n","      # Load the EfficientNetB0 model with pre-trained weights (include_top=False)\n","      base_model = EfficientNetB0(weights='imagenet', include_top=False)\n","\n","      # Add a global average pooling layer and a fully connected layer for classification\n","      x = base_model.output\n","      x = GlobalAveragePooling2D()(x)\n","      x = Dense(1024, activation='relu')(x)\n","      predictions = Dense(len(os.listdir(train_dir)), activation='softmax')(x)\n","\n","      # Create the model\n","      model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n","      custom_optimizer = Adam(learning_rate=0.00003)\n","\n","      # Compile the model\n","      model.compile(optimizer=custom_optimizer,\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","\n","      # Define callbacks\n","      model_checkpoint = ModelCheckpoint(model_path + 'save_model/model.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')\n","      early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n","\n","      # Train the model\n","      num_epochs = 50\n","      history = model.fit(train_generator,\n","                          epochs=num_epochs,\n","                          validation_data=validation_generator,\n","                          callbacks=[model_checkpoint, early_stopping])\n","\n","      # Save the trained model\n","      model.save(model_path + 'save_model/pet_classification_efficientnet_b0.h5')\n","\n","    @staticmethod\n","    def draw_graph(filename):\n","        with open(model_path + 'acc_history/'+ filename, 'r') as json_file:\n","            data = json.load(json_file)\n","            acc = data['acc']\n","            val_acc = data['val_acc']\n","            loss = data['loss']\n","            val_loss = data['val_loss']\n","\n","            epochs = range(len(acc))\n","            plt.figure(figsize=(100, 100))\n","            plt.subplot(211)\n","            plt.plot(epochs, acc, 'r', label='Training accuracy')\n","            plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","            plt.title('Training and validation accuracy')\n","            plt.legend(loc=0)\n","\n","            plt.subplot(212)\n","            plt.plot(epochs, loss, 'r', label='Training loss')\n","            plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","            plt.title('Training and validation loss')\n","            plt.legend(loc=0)\n","\n","            plt.show()\n","\n","    @staticmethod\n","    def predict_pet(img_path, real_model_path, label_list):\n","      print(img_path)\n","      model = keras.models.load_model(real_model_path)\n","      img = image.load_img(img_path, target_size=(224, 224))\n","      img_array = image.img_to_array(img)\n","      img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","      img_array = img_array / 255.0  # Rescale to the range [0, 1]\n","\n","      # Make the prediction\n","      prediction = model.predict(img_array)\n","      print(prediction)\n","\n","      arr = prediction[0].tolist()\n","      list = []\n","      for index, value in enumerate(arr):\n","        list.append((label_list[index], value))\n","      list.sort(key = lambda x : -x[1])\n","\n","      for i in range(3):\n","        print(\"유사도 \" + str(i+1) + \"등 : \" + str(list[i][0]) + \", 정확도 \" + str(list[i][1]))\n","      print()\n","      return list[0][0]\n"],"metadata":{"id":"bpeyL62fPGZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","  model = EfficientNet()\n","  model.training_model()\n","  print(\"학습 완료\")\n","train()"],"metadata":{"id":"hcMIeLsMOvWD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# [Step 4] 예측"],"metadata":{"id":"aY6eGpWd6XYb"}},{"cell_type":"code","source":["def predict() :\n","  test_val = os.listdir(data_path + 'test_img')\n","  test_val.sort()\n","\n","  test_count = 0\n","  correct_count = 0\n","  for val in test_val :\n","    test_img = os.listdir(data_path + 'test_img/' + str(val))\n","    test_img.sort()\n","    for img_name in test_img :\n","      img_path = data_path + 'test_img/' + str(val) + '/' + str(img_name)\n","      real_model_path = model_path + 'save_model/pet_classification_efficientnet_b0.h5'\n","      result = EfficientNet.predict_pet(img_path, real_model_path, test_val)\n","\n","      test_count += 1\n","      if str(result) == str(val) :\n","        correct_count += 1\n","      print(\"%0.2f%%\" % (correct_count / test_count * 100))\n","predict()"],"metadata":{"id":"4p1yykXf6asR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def graph():\n","  filename = 'acc_history_v20231151726.txt'\n","  EfficientNet.draw_graph(filename)\n","graph()"],"metadata":{"id":"81-3r41YOZUN"},"execution_count":null,"outputs":[]}]}